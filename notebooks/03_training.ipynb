{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "import pickle\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(\"notebooks\"), '..')))\n",
    "\n",
    "from utils.func_preprocessing import *\n",
    "from utils.func_classification import *\n",
    "from utils.func_training import *\n",
    "from utils.utils import *\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from config.config import (\n",
    "    DATASET_NAME,\n",
    "    YEARS_TRAINING,\n",
    "    LIST_TYPE,\n",
    "    PREPROCESSING_TRANSFORMATION,\n",
    "    CLASS_UNDER_SAMPLE,\n",
    "    MODEL,\n",
    "    MODEL_NAME,\n",
    "    PARAMS,\n",
    "    SAVE_PREDICT_TO_XLSX,\n",
    "    SAVE_PKL_MODEL,\n",
    "    TRAINING_INFO,\n",
    "    N_CLASS\n",
    ")\n",
    "\n",
    "if PREPROCESSING_TRANSFORMATION:\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from imblearn.under_sampling import RandomUnderSampler\n",
    "    from collections import Counter\n",
    "    \n",
    "if CLASS_UNDER_SAMPLE:\n",
    "    from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "df = pd.read_csv(f\"../dataset/{DATASET_NAME}.csv\")\n",
    "\n",
    "# Drop 'Unnamed: 0' column if it exists\n",
    "if \"Unnamed: 0\" in df.columns:\n",
    "    df = df.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "df.intero_diagnosi_princip = df.intero_diagnosi_princip.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colonna target con classificazione macropat\n",
    "# df['y'] = df['intero_diagnosi_princip'].apply(classificazione_macropat)\n",
    "# df['y'] = df['intero_diagnosi_princip'].apply(classificazione_poche_macropat)\n",
    "# df['y'] = df.apply(lambda row: classificazione_tre_macropat(row['lettera_diagnosi_princip'], row['intero_diagnosi_princip']), axis=1)\n",
    "# df['y'] = df.apply(lambda row: classificazione_sei_macropat(row['lettera_diagnosi_princip'], row['intero_diagnosi_princip']), axis=1)\n",
    "# df['y'] = df.apply(lambda row: classificazione_sei_macropat_v2(row['lettera_diagnosi_princip'], row['intero_diagnosi_princip']), axis=1)\n",
    "# df['y'] = df.apply(lambda row: classificazione_sette_macropat(row['lettera_diagnosi_princip'], row['intero_diagnosi_princip']), axis=1)\n",
    "# df['y'] = df.apply(lambda row: classificazione_18_macropat(row['lettera_diagnosi_princip'], row['intero_diagnosi_princip']), axis=1)\n",
    "# df['y'] = df.apply(lambda row: class_macropat_letteremappate(row['lettera_diagnosi_princip'], row['intero_diagnosi_princip']), axis=1)\n",
    "# df['y'] = df.y.apply(reduce_6class_letteremappate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if N_CLASS == 6:\n",
    "    df['y'] = df.apply(lambda row: class_macropat_letteremappate(row['lettera_diagnosi_princip'], row['intero_diagnosi_princip']), axis=1)\n",
    "    df['y'] = df.y.apply(reduce_6class_letteremappate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimino le altre colonne target\n",
    "col_to_drop = [\"COD_DIAGNOSI_PRINCIPALE\", \"lettera_diagnosi_princip\", \"intero_diagnosi_princip\", \"decimali_diagnosi_princip\"]\n",
    "df = df.drop(columns=col_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection da KDE:\n",
    "### Escludere:  'AG_K', 'GLU','LAC', 'PO2', 'HCO3', 'PCO2_T', 'PCO2', "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DATA'] = pd.to_datetime(df['DATA'])\n",
    "\n",
    "# Estrae il giorno dell'anno\n",
    "df['day_of_year'] = df['DATA'].apply(lambda x: x.timetuple().tm_yday)\n",
    "\n",
    "# Calcola le nuove colonne \"sin_day\" e \"cos_day\"\n",
    "df['sin_day'] = np.sin(2 * np.pi * df['day_of_year'] / 365)\n",
    "df['cos_day'] = np.cos(2 * np.pi * df['day_of_year'] / 365)\n",
    "\n",
    "# Elimino colonne anagrafica\n",
    "df = df.drop(columns=['ID_ANAGRAFICA', 'DTN', 'DATA_INGRESSO', 'DATA',\n",
    "                      'DATA_USCITA', 'NCAMPIONE', 'NACCESSO', 'STATO', 'REPARTO_PZ', 'day_of_year'])  # 'SESSO', 'ETA', 'TIPO',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df = df.dropna()\n",
    "df = df.loc[df.CBASE != '.....']\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df.TIPO.isin([\"Arterioso\", \"Venoso\"])]\n",
    "df.TIPO = df.TIPO.astype('category')\n",
    "\n",
    "df.SESSO = df.SESSO.astype('category')\n",
    "df.class_symptom = df.class_symptom.astype('category')\n",
    "\n",
    "df.ETA = df.ETA.astype(int)\n",
    "\n",
    "df.THB2 = df.THB2.astype(float)\n",
    "df.MOSM = df.MOSM.astype(float)\n",
    "df.CBASE = df.CBASE.astype(float)\n",
    "df.METHB = df.METHB.astype(float)\n",
    "df.O2HB = df.O2HB.astype(float)\n",
    "df.COHB = df.COHB.astype(float)\n",
    "df.RHB = df.RHB.astype(float)\n",
    "df.PF = df.PF.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection: drop columns with high correlation (circa 1)\n",
    "df = df.drop(columns=[ \"HCT\", \"PCO2\", \"PHT\"]) # \"PO21\",\n",
    "\n",
    "# V2\n",
    "df = df.drop(columns=[\"THB\", \"RHB\", \"SO2\"]) # SO2 PRIMA ERA SO21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleziona arterioso/venoso (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df.TIPO.isin(LIST_TYPE)]\n",
    "\n",
    "if len(LIST_TYPE)==1:\n",
    "    df = df.drop(columns=[\"TIPO\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-test split 80-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separiamo le feature (X) e la target (y)\n",
    "X = df.drop(columns=['y'])\n",
    "y = df['y']\n",
    "\n",
    "# Eseguiamo lo split in training e test set (80% training, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing trasformazioni (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PREPROCESSING_TRANSFORMATION:\n",
    "    # Copia del DataFrame di training\n",
    "    X_train_transformed = X_train.copy()\n",
    "\n",
    "    # Variabili con distribuzione sbilanciata a destra (Logaritmo normale)\n",
    "    X_train_transformed['O2HB'] = np.log1p(X_train_transformed['O2HB'])  # np.log1p gestisce automaticamente i valori nulli e zero\n",
    "\n",
    "    # Variabili con distribuzione sbilanciata a sinistra (logaritmo del valore negativo)\n",
    "    for col in ['COHB', 'GLU', 'LAC', 'P50_ACT', 'PF', 'PO2_T']:\n",
    "        X_train_transformed[col] = X_train_transformed[col].astype(float)\n",
    "        X_train_transformed[col] = np.log1p(X_train_transformed[col])  # -df[col] per rendere positiva la distribuzione\n",
    "\n",
    "    # Normalizzazione Min-Max per le variabili indicate\n",
    "    scaler = MinMaxScaler()\n",
    "    cols_to_scale = ['B', 'CBASE', 'METHB', 'CL', 'NA', 'KP', 'HCO3', 'PCO2_T', 'MOSM', 'THB2', 'TO2', 'ETA']\n",
    "    X_train_transformed[cols_to_scale] = scaler.fit_transform(X_train_transformed[cols_to_scale])\n",
    "\n",
    "    # Trasformazione categorica\n",
    "    X_train_transformed['FIO2'] = X_train_transformed['FIO2'].astype('category')\n",
    "\n",
    "    # Arrotonda 'TC' a 0.5 e converte in categorico\n",
    "    X_train_transformed['TC'] = (X_train_transformed['TC'] / 0.5).round() * 0.5\n",
    "    X_train_transformed['TC'] = X_train_transformed['TC'].astype('category')\n",
    "\n",
    "    X_train = X_train_transformed.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bilanciamento Classi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CLASS_UNDER_SAMPLE:\n",
    "    undersample = RandomUnderSampler(sampling_strategy='auto', random_state=42)\n",
    "    X_train_res, y_train_res = undersample.fit_resample(X_train, y_train)\n",
    "\n",
    "    X_train, y_train = X_train_res.copy(), y_train_res.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODEL == \"Pycaret\":\n",
    "    # Train model\n",
    "    model, feature_importances_df, pycaret_model_name, setup_config, metrics_df = train_pycaret(X_train, y_train, PARAMS, N_CLASS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODEL == \"Pycaret\":\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.barplot(x='Importance', y='Feature', data=feature_importances_df)\n",
    "    plt.title('Importanza delle Feature')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PREPROCESSING_TRANSFORMATION:\n",
    "    # Copia del DataFrame di test\n",
    "    X_test_transformed = X_test.copy()\n",
    "\n",
    "    # Stesse trasformazioni del training set\n",
    "\n",
    "    # Variabili con distribuzione sbilanciata a destra (Logaritmo normale)\n",
    "    X_test_transformed['O2HB'] = np.log1p(X_test_transformed['O2HB'])\n",
    "\n",
    "    # Variabili con distribuzione sbilanciata a sinistra (logaritmo del valore negativo)\n",
    "    for col in ['COHB', 'GLU', 'LAC', 'P50_ACT', 'PF', 'PO2_T']:\n",
    "        X_test_transformed[col] = np.log1p(X_test_transformed[col])\n",
    "\n",
    "    # Applicare lo stesso scaler usato sul training set\n",
    "    X_test_transformed[cols_to_scale] = scaler.transform(X_test_transformed[cols_to_scale])\n",
    "\n",
    "    # Trasformazione categorica\n",
    "    X_test_transformed['FIO2'] = X_test_transformed['FIO2'].astype('category')\n",
    "\n",
    "    # Arrotonda 'TC' a 0.5 e converte in categorico\n",
    "    X_test_transformed['TC'] = (X_test_transformed['TC'] / 0.5).round() * 0.5\n",
    "    X_test_transformed['TC'] = X_test_transformed['TC'].astype('category')\n",
    "\n",
    "    X_test = X_test_transformed.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effettuiamo le predizioni sul test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Valutiamo il modello\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "D_classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print('Classification Report:')\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "labels = model.classes_ \n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=labels, columns=labels)\n",
    "conf_matrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE_PREDICT_TO_XLSX:\n",
    "    test_temp = X_test.copy()\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)\n",
    "    test_temp[[\"Prob_0\",\"Prob_1\",\"Prob_2\",\"Prob_3\",\"Prob_4\", \"Prob_5\"]] = y_pred_proba\n",
    "    test_temp[\"y_pred\"] = y_pred\n",
    "    test_temp[\"y_true\"] = y_test\n",
    "    test_temp = test_temp.reset_index(drop=True)\n",
    "    today = datetime.now().strftime('%y%m%d')\n",
    "    test_temp.to_excel(f\"./notes/{today}_pred_with_prob_{N_CLASS}_{TRAINING_INFO}.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance sul training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effettuiamo le predizioni sul training set\n",
    "y_pred_train = model.predict(X_train)\n",
    "\n",
    "# Valutiamo il modello\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "classification_rep_train = classification_report(y_train, y_pred_train)\n",
    "D_classification_rep_train = classification_report(y_train, y_pred_train, output_dict=True)\n",
    "\n",
    "print(f'Accuracy: {accuracy_train:.4f}')\n",
    "print('Classification Report:')\n",
    "print(classification_rep_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix sul training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix_train = confusion_matrix(y_train, y_pred_train)\n",
    "labels = model.classes_ \n",
    "conf_matrix_df_train = pd.DataFrame(conf_matrix_train, index=labels, columns=labels)\n",
    "conf_matrix_df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE_PKL_MODEL:\n",
    "    with open(f\"../models/{MODEL_NAME}.pkl\", \"wb\") as file:\n",
    "        pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log to MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codice che serve per mettere in un dizionario \"leggibile da MLFlow\" il \"classification report\" calcolato sul test set\n",
    "D_metric = {}\n",
    "for classe in D_classification_rep:\n",
    "    if type(D_classification_rep[classe]) == dict:\n",
    "        for metric in D_classification_rep[classe]:\n",
    "            D_metric[f\"{classe}_{metric}\"] = D_classification_rep[classe][metric]\n",
    "D_metric[\"accuracy\"] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codice che serve per mettere in un dizionario \"leggibile da MLFlow\" il \"classification report\" calcolato sul training set\n",
    "D_metric_train = {}\n",
    "for classe_train in D_classification_rep_train:\n",
    "    if type(D_classification_rep_train[classe_train]) == dict:\n",
    "        for metric_train in D_classification_rep_train[classe_train]:\n",
    "            D_metric_train[f\"{classe_train}_{metric_train}_train\"] = D_classification_rep_train[classe_train][metric_train]\n",
    "D_metric_train[\"accuracy_train\"] = accuracy_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(LIST_TYPE)==2:\n",
    "    type_mlflow = \"Tutti\"\n",
    "else:\n",
    "    type_mlflow = LIST_TYPE[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dizionario che va modificato per inserire tutti i parametri della run\n",
    "D_to_set = {\n",
    "    \"Training_info\" : TRAINING_INFO,        \n",
    "    \"func_classification\" : f\"Funzione per {N_CLASS}\",    \n",
    "    \"n_class\" : len(df.y.unique()),\n",
    "    \"columns\" : str(list(X_train.columns)),\n",
    "    \"func_training\" : \"train_pycaret\",                       \n",
    "    \"model_name\" :  MODEL_NAME,\n",
    "    \"dataset_name\" : DATASET_NAME,\n",
    "    \"years_training\" : YEARS_TRAINING,\n",
    "    \"data_ora\" : datetime.now(),\n",
    "    \"TIPO\": type_mlflow,                                          \n",
    "    \"len_train\" : X_train.shape[0],\n",
    "    \"len_test\" : X_test.shape[0],\n",
    "    \"class_under_sample\": CLASS_UNDER_SAMPLE,\n",
    "    \"coeff_of_variation_train\" : calculate_coefficient_of_variation(y_train),\n",
    "    \"coeff_of_variation_test\" : calculate_coefficient_of_variation(y_test),\n",
    "    \"skewness_train\" : calculate_skewness(y_train),\n",
    "    \"skewness_test\" : calculate_skewness(y_test),\n",
    "}\n",
    "\n",
    "if MODEL == \"Pycaret\":\n",
    "    D_to_set[\"pycaret_model_name\"] = pycaret_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set our tracking server URI for logging\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8080\")\n",
    "\n",
    "# Create a new MLflow Experiment\n",
    "mlflow.set_experiment(\"MLClinicalProb_exten\")\n",
    "\n",
    "# Start an MLflow run\n",
    "with mlflow.start_run():\n",
    "    \n",
    "    # Log parameters to MLflow\n",
    "    mlflow.log_params(PARAMS)\n",
    "    \n",
    "    # Log metrics to MLflow\n",
    "    for key in D_metric:\n",
    "        mlflow.log_metric(key, D_metric[key])\n",
    "    for key_train in D_metric_train:\n",
    "        mlflow.log_metric(key_train, D_metric_train[key_train])\n",
    "    \n",
    "    # Set tags in MLflow\n",
    "    for key in D_to_set:\n",
    "        mlflow.set_tag(key, D_to_set[key])\n",
    "    \n",
    "    # Infer the model signature\n",
    "    signature = infer_signature(X_train, model.predict(X_train))\n",
    "    \n",
    "    # Log the model\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        sk_model=model,\n",
    "        artifact_path=\"model_mlclinicalprob\",\n",
    "        signature=signature,\n",
    "        input_example=X_train,\n",
    "        registered_model_name=MODEL_NAME,\n",
    "    )\n",
    "\n",
    "\n",
    "    if MODEL == \"Pycaret\":\n",
    "        # Log feature importance as Artifacts\n",
    "        feature_importance_file = \"feature_importance.csv\"\n",
    "        feature_importances_df.to_csv(feature_importance_file, index=False)\n",
    "        mlflow.log_artifact(feature_importance_file, artifact_path=\"pycaret\")\n",
    "        os.remove(feature_importance_file)\n",
    "\n",
    "        # Log pycaret setup_config as Artifacts\n",
    "        setup_config_file = \"setup_config.csv\"\n",
    "        setup_config.to_csv(setup_config_file, index=False)\n",
    "        mlflow.log_artifact(setup_config_file, artifact_path=\"pycaret\")\n",
    "        os.remove(setup_config_file)\n",
    "\n",
    "        # Log pycaret metrics_df as Artifacts\n",
    "        metrics_df_file = \"metrics_df.csv\"\n",
    "        metrics_df.to_csv(metrics_df_file, index=False)\n",
    "        mlflow.log_artifact(metrics_df_file, artifact_path=\"pycaret\")\n",
    "        os.remove(metrics_df_file)\n",
    "\n",
    "    # Log confusion matrix test as Artifacts\n",
    "    conf_matrix_file = \"conf_matrix_df_test.csv\"\n",
    "    conf_matrix_df.to_csv(conf_matrix_file, index=False)\n",
    "    mlflow.log_artifact(conf_matrix_file, artifact_path=\"conf_matrix\")\n",
    "    os.remove(conf_matrix_file)\n",
    "\n",
    "    # Log confusion matrix train as Artifacts\n",
    "    conf_matrix_train_file = \"conf_matrix_df_train.csv\"\n",
    "    conf_matrix_df_train.to_csv(conf_matrix_train_file, index=False)\n",
    "    mlflow.log_artifact(conf_matrix_train_file, artifact_path=\"conf_matrix\")\n",
    "    os.remove(conf_matrix_train_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clinicalprobenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
